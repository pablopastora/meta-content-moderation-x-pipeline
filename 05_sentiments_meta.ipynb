{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDFHn3G0avKl"
      },
      "outputs": [],
      "source": [
        "#@title Traducción y análisis de sentimientos\n",
        "\n",
        "# ============================================================\n",
        "# COLAB: Traducción por país + Sentiment EN\n",
        "# CON MENSAJES DE PROGRESO\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install pandas numpy transformers sentencepiece accelerate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
        "\n",
        "print(\"\\n[INFO] Inicio del pipeline\")\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Cargar dataset\n",
        "# ----------------------------\n",
        "PATH = \"replies_meta_desde_urls.csv\"\n",
        "df = pd.read_csv(PATH, sep=\";\", encoding=\"latin1\", engine=\"python\")\n",
        "\n",
        "df[\"text\"] = df[\"text\"].astype(str).fillna(\"\").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
        "df[\"_user_original_norm\"] = df[\"user_original\"].astype(str).str.lower().str.strip()\n",
        "\n",
        "media_to_country = {\n",
        "    \"@20m\": \"España\",\n",
        "    \"@el_pais\": \"España\",\n",
        "    \"@eldiarioes\": \"España\",\n",
        "    \"@elmundoes\": \"España\",\n",
        "    \"@ensonhaber\": \"Turquía\",\n",
        "    \"@gazetesozcu\": \"Turquía\",\n",
        "    \"@haberturk\": \"Turquía\",\n",
        "    \"@nypost\": \"Estados Unidos\",\n",
        "    \"@nytimes\": \"Estados Unidos\",\n",
        "    \"@washingtonpost\": \"Estados Unidos\",\n",
        "    \"@wsj\": \"Estados Unidos\",\n",
        "    \"@usatoday\": \"Estados Unidos\",\n",
        "}\n",
        "df[\"pais\"] = df[\"_user_original_norm\"].map(media_to_country)\n",
        "\n",
        "mask_nonempty = df[\"text\"].ne(\"\")\n",
        "print(f\"[INFO] Total filas con texto: {mask_nonempty.sum()}\")\n",
        "\n",
        "print(\"\\n[INFO] Distribución por país:\")\n",
        "print(df[\"pais\"].value_counts(dropna=False))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"\\n[INFO] Device: {device}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Traducción (solo España y Turquía)\n",
        "# ----------------------------\n",
        "print(\"\\n[INFO] Cargando modelo de traducción (NLLB)...\")\n",
        "TRANSLATION_MODEL = \"facebook/nllb-200-distilled-600M\"\n",
        "trans_tokenizer = AutoTokenizer.from_pretrained(TRANSLATION_MODEL)\n",
        "trans_model = AutoModelForSeq2SeqLM.from_pretrained(TRANSLATION_MODEL).to(device)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def translate_to_english(texts, src_lang_code, label, batch_size=16, max_length=256):\n",
        "    trans_tokenizer.src_lang = src_lang_code\n",
        "    outputs = []\n",
        "    total = len(texts)\n",
        "    n_batches = (total + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in range(0, total, batch_size):\n",
        "        b = i // batch_size + 1\n",
        "        print(f\"[TRADUCCIÓN {label}] Lote {b}/{n_batches}\")\n",
        "        batch = texts[i:i+batch_size]\n",
        "\n",
        "        enc = trans_tokenizer(\n",
        "            batch,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "        ).to(device)\n",
        "\n",
        "        gen = trans_model.generate(\n",
        "            **enc,\n",
        "            forced_bos_token_id=trans_tokenizer.convert_tokens_to_ids(\"eng_Latn\"),\n",
        "            max_new_tokens=max_length,\n",
        "            num_beams=4,\n",
        "        )\n",
        "        outputs.extend(trans_tokenizer.batch_decode(gen, skip_special_tokens=True))\n",
        "\n",
        "    print(f\"[TRADUCCIÓN {label}] Finalizada\")\n",
        "    return outputs\n",
        "\n",
        "df[\"text_en\"] = \"\"\n",
        "\n",
        "# EEUU → copiar\n",
        "mask_us = mask_nonempty & (df[\"pais\"] == \"Estados Unidos\")\n",
        "print(f\"\\n[INFO] EEUU → no se traduce: {mask_us.sum()} textos\")\n",
        "df.loc[mask_us, \"text_en\"] = df.loc[mask_us, \"text\"]\n",
        "\n",
        "# España → traducir\n",
        "mask_es = mask_nonempty & (df[\"pais\"] == \"España\")\n",
        "print(f\"[INFO] España → se traducen: {mask_es.sum()} textos\")\n",
        "if mask_es.any():\n",
        "    df.loc[mask_es, \"text_en\"] = translate_to_english(\n",
        "        df.loc[mask_es, \"text\"].tolist(), \"spa_Latn\", label=\"ES\"\n",
        "    )\n",
        "\n",
        "# Turquía → traducir\n",
        "mask_tr = mask_nonempty & (df[\"pais\"] == \"Turquía\")\n",
        "print(f\"[INFO] Turquía → se traducen: {mask_tr.sum()} textos\")\n",
        "if mask_tr.any():\n",
        "    df.loc[mask_tr, \"text_en\"] = translate_to_english(\n",
        "        df.loc[mask_tr, \"text\"].tolist(), \"tur_Latn\", label=\"TR\"\n",
        "    )\n",
        "\n",
        "# Fallback\n",
        "mask_left = mask_nonempty & df[\"text_en\"].eq(\"\")\n",
        "df.loc[mask_left, \"text_en\"] = df.loc[mask_left, \"text\"]\n",
        "\n",
        "print(\"\\n[INFO] Traducción completada\")\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Sentiment en inglés\n",
        "# ----------------------------\n",
        "print(\"\\n[INFO] Cargando modelo de sentimiento...\")\n",
        "SENT_MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "sent_tokenizer = AutoTokenizer.from_pretrained(SENT_MODEL)\n",
        "sent_model = AutoModelForSequenceClassification.from_pretrained(SENT_MODEL).to(device)\n",
        "\n",
        "labels = {int(k): v.lower() for k, v in sent_model.config.id2label.items()}\n",
        "neg_i = [k for k,v in labels.items() if \"neg\" in v][0]\n",
        "pos_i = [k for k,v in labels.items() if \"pos\" in v][0]\n",
        "\n",
        "@torch.inference_mode()\n",
        "def sentiment_probs(texts, batch_size=32, max_length=128):\n",
        "    outputs = []\n",
        "    total = len(texts)\n",
        "    n_batches = (total + batch_size - 1) // batch_size\n",
        "\n",
        "    for i in range(0, total, batch_size):\n",
        "        b = i // batch_size + 1\n",
        "        print(f\"[SENTIMENT] Lote {b}/{n_batches}\")\n",
        "        batch = texts[i:i+batch_size]\n",
        "\n",
        "        enc = sent_tokenizer(\n",
        "            batch,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "        ).to(device)\n",
        "\n",
        "        logits = sent_model(**enc).logits\n",
        "        outputs.append(torch.softmax(logits, dim=1).detach().cpu().numpy())\n",
        "\n",
        "    print(\"[SENTIMENT] Finalizado\")\n",
        "    return np.vstack(outputs)\n",
        "\n",
        "texts_en = df[\"text_en\"].astype(str).tolist()\n",
        "probs = sentiment_probs(texts_en)\n",
        "\n",
        "df[\"polaridad\"] = probs[:, pos_i] - probs[:, neg_i]\n",
        "\n",
        "print(\"\\n[INFO] Polaridad media por país:\")\n",
        "print(df.groupby(\"pais\")[\"polaridad\"].mean())\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Guardar\n",
        "# ----------------------------\n",
        "out_path = \"replies_meta_en_sentiment.csv\"\n",
        "df.drop(columns=[\"_user_original_norm\"], errors=\"ignore\").to_csv(out_path, index=False, encoding=\"utf-8\")\n",
        "print(f\"\\n[OK] Archivo guardado: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#@title GRÁFICOS (desde replies_meta_en_sentiment.csv)\n",
        "#   - Lee el CSV ya procesado (sin volver a traducir)\n",
        "#   - Genera y guarda PNGs (300 dpi) listos para paper\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install pandas numpy matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Cargar resultados\n",
        "# ----------------------------\n",
        "PATH_OUT = \"replies_meta_en_sentiment.csv\"\n",
        "df = pd.read_csv(PATH_OUT, encoding=\"utf-8\")\n",
        "\n",
        "# Asegura tipos\n",
        "df[\"polaridad\"] = pd.to_numeric(df[\"polaridad\"], errors=\"coerce\")\n",
        "df[\"pais\"] = df[\"pais\"].astype(str)\n",
        "\n",
        "# Filtrado básico\n",
        "dfp = df.dropna(subset=[\"polaridad\", \"pais\"]).copy()\n",
        "dfp = dfp[dfp[\"polaridad\"].between(-1, 1, inclusive=\"both\")]\n",
        "\n",
        "# Normaliza medio\n",
        "dfp[\"medio_norm\"] = dfp[\"user_original\"].astype(str).str.strip().str.lower()\n",
        "\n",
        "# Orden fijo de países\n",
        "country_order = [\"España\", \"Estados Unidos\", \"Turquía\"]\n",
        "country_order = [c for c in country_order if c in dfp[\"pais\"].unique()]\n",
        "\n",
        "print(\"N por país:\")\n",
        "print(dfp[\"pais\"].value_counts())\n",
        "\n",
        "# ----------------------------\n",
        "# 2) BOXplot polaridad por país (recomendado)\n",
        "# ----------------------------\n",
        "data_by_country = [dfp.loc[dfp[\"pais\"] == c, \"polaridad\"].values for c in country_order]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.boxplot(data_by_country, labels=country_order, showfliers=False)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.ylabel(\"Polaridad (p_pos − p_neg)\")\n",
        "plt.title(\"Distribución de la polaridad de las respuestas por país\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig1_boxplot_polaridad_pais.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Histograma/densidad por país (superpuesto)\n",
        "# ----------------------------\n",
        "plt.figure(figsize=(8, 5))\n",
        "for c in country_order:\n",
        "    vals = dfp.loc[dfp[\"pais\"] == c, \"polaridad\"].values\n",
        "    plt.hist(vals, bins=30, alpha=0.5, density=True, label=c)\n",
        "plt.axvline(0, linewidth=1)\n",
        "plt.xlabel(\"Polaridad (p_pos − p_neg)\")\n",
        "plt.ylabel(\"Densidad\")\n",
        "plt.title(\"Distribución de polaridad por país\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig2_hist_polaridad_pais.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Barras: polaridad media por país (con N)\n",
        "# ----------------------------\n",
        "means = dfp.groupby(\"pais\")[\"polaridad\"].mean().reindex(country_order)\n",
        "counts = dfp.groupby(\"pais\")[\"polaridad\"].count().reindex(country_order)\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.bar(means.index, means.values)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.ylabel(\"Polaridad media\")\n",
        "plt.title(\"Polaridad media de respuestas por país\")\n",
        "# Anotar N encima\n",
        "for i, c in enumerate(means.index):\n",
        "    plt.text(i, means.values[i], f\"N={int(counts[c])}\", ha=\"center\", va=\"bottom\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig3_media_polaridad_pais.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Polaridad media por medio (Top/Bottom N)\n",
        "# ----------------------------\n",
        "N = 10  # ajusta a 5/10/15\n",
        "means_media = dfp.groupby(\"medio_norm\")[\"polaridad\"].mean().sort_values()\n",
        "bottom = means_media.head(N)\n",
        "top = means_media.tail(N)\n",
        "combo = pd.concat([bottom, top])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(combo.index, combo.values)\n",
        "plt.axvline(0, linewidth=1)\n",
        "plt.xlabel(\"Polaridad media\")\n",
        "plt.title(f\"Polaridad media por medio (Bottom {N} y Top {N})\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig4_media_polaridad_medio_topbottom.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 6) Boxplot por medio (solo medios con N mínimo)\n",
        "# ----------------------------\n",
        "MIN_N = 30  # cambia a 20/30/50\n",
        "counts_media = dfp[\"medio_norm\"].value_counts()\n",
        "keep = counts_media[counts_media >= MIN_N].index.tolist()\n",
        "dfm = dfp[dfp[\"medio_norm\"].isin(keep)].copy()\n",
        "\n",
        "# Orden de medios por media\n",
        "order_media = dfm.groupby(\"medio_norm\")[\"polaridad\"].mean().sort_values().index.tolist()\n",
        "data_by_media = [dfm.loc[dfm[\"medio_norm\"] == m, \"polaridad\"].values for m in order_media]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.boxplot(data_by_media, labels=order_media, showfliers=False)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.ylabel(\"Polaridad (p_pos − p_neg)\")\n",
        "plt.title(f\"Distribución de polaridad por medio (N≥{MIN_N})\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig5_boxplot_polaridad_medio.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 7) (Recomendado) Versión \"sin Turquía\" para paper (si N es muy bajo)\n",
        "# ----------------------------\n",
        "df_no_tr = dfp[dfp[\"pais\"] != \"Turquía\"].copy()\n",
        "country_order_no_tr = [c for c in [\"España\", \"Estados Unidos\"] if c in df_no_tr[\"pais\"].unique()]\n",
        "data_no_tr = [df_no_tr.loc[df_no_tr[\"pais\"] == c, \"polaridad\"].values for c in country_order_no_tr]\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.boxplot(data_no_tr, labels=country_order_no_tr, showfliers=False)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.ylabel(\"Polaridad (p_pos − p_neg)\")\n",
        "plt.title(\"Distribución de la polaridad (España vs EEUU)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig6_boxplot_polaridad_pais_sin_turquia.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Figuras guardadas:\")\n",
        "print([\n",
        "    \"fig1_boxplot_polaridad_pais.png\",\n",
        "    \"fig2_hist_polaridad_pais.png\",\n",
        "    \"fig3_media_polaridad_pais.png\",\n",
        "    \"fig4_media_polaridad_medio_topbottom.png\",\n",
        "    \"fig5_boxplot_polaridad_medio.png\",\n",
        "    \"fig6_boxplot_polaridad_pais_sin_turquia.png\",\n",
        "])\n",
        "\n",
        "# Para descargar en Colab (opcional):\n",
        "# from google.colab import files\n",
        "# for f in [\n",
        "#   \"fig1_boxplot_polaridad_pais.png\",\n",
        "#   \"fig2_hist_polaridad_pais.png\",\n",
        "#   \"fig3_media_polaridad_pais.png\",\n",
        "#   \"fig4_media_polaridad_medio_topbottom.png\",\n",
        "#   \"fig5_boxplot_polaridad_medio.png\",\n",
        "#   \"fig6_boxplot_polaridad_pais_sin_turquia.png\",\n",
        "# ]:\n",
        "#     files.download(f)\n"
      ],
      "metadata": {
        "id": "UTlUQwYjbJKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BNFYbKSgbC1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}